@article{kingma_welling_auto_encoding,
  title   = {Auto-Encoding Variational Bayes},
  author  = {Diederik P. Kingma and Max Welling},
  year    = {2012}
}

@misc{example,
  author = {Author Name},
  title = {Title of the Webpage},
  year = {2023},
  url = {https://example.com},
  note = {Accessed: 2023-07-27}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{fawaz2019long,
  title={A survey on long short-term memory networks for time series prediction},
  author={Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={534},
  pages={122--315},
  year={2019},
  publisher={Elsevier}
}


@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

@misc{thispersondoesnotexist,
  author = {Phillip Wang},
  title = {This Person Does Not Exist},
  year = {2019},
  howpublished = {\url{https://thispersondoesnotexist.com}},
  note = {Accessed: 2024-08-03}
}

@article{naveed2023overview,
  title={A Comprehensive Overview of Large Language Models},
  author={Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
  journal={arXiv preprint arXiv:2307.06435},
  year={2023}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}


@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2006.11239},
  year={2020}
}


@article{yang2022diffusion,
  title={Diffusion Models: A Comprehensive Survey of Methods and Applications},
  author={Yang Song, Stefano Ermon},
  journal={arXiv preprint arXiv:2209.00796},
  year={2022},
  url={https://arxiv.org/abs/2209.00796}
}



@article{dhariwal2021diffusion,
  title={Diffusion Models Beat GANs on Image Synthesis},
  author={Dhariwal, Prafulla and Nichol, Alex},
  year={2021},
  journal={arXiv preprint arXiv:2105.05233},
  url={https://arxiv.org/abs/2105.05233}
}

@article{nichol2021improved,
  title={Improved Denoising Diffusion Probabilistic Models},
  author={Nichol, Alex and Dhariwal, Prafulla},
  year={2021},
  journal={arXiv preprint arXiv:2102.09672},
  url={https://arxiv.org/abs/2102.09672}
}

@article{ramesh2022hierarchical,
  title={Hierarchical Text-Conditional Image Generation with CLIP Latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  year={2022},
  journal={arXiv preprint arXiv:2204.06125},
  url={https://arxiv.org/abs/2204.06125}
}


@article{yang2023survey,
  title={A Survey on Diffusion Models for Time Series and Spatio-Temporal Data},
  author={Yang, Yiyuan and Jin, Ming and Wen, Haomin and Zhang, Chaoli and Liang, Yuxuan and Ma, Lintao and Wang, Yi and Liu, Chenghao and Yang, Bin and Xu, Zenglin and Bian, Jiang and Pan, Shirui and Wen, Qingsong},
  year={2023},
  journal={arXiv preprint arXiv:2301.08548},
  url={https://arxiv.org/abs/2301.08548}
}

@article{Mrozek2023,
    title={From Corrective to Predictive Maintenance—A Review of Maintenance Approaches for the Power Industry},
    author={Dariusz Mrozek and others},
    journal={Sensors},
    volume={23},
    number={13},
    pages={5970},
    year={2023},
    doi={10.3390/s23135970}
}

@article{Lee2020,
    title={Challenges and Opportunities of Condition-based Predictive Maintenance},
    author={Jay Lee and others},
    journal={Procedia CIRP},
    volume={88},
    pages={241--245},
    year={2020},
    doi={10.1016/j.procir.2020.05.042}
}


@article{Khelif2022,
    title={Towards Multi-model Approaches to Predictive Maintenance},
    author={Rafik Khelif and others},
    journal={Journal of Intelligent Manufacturing},
    volume={33},
    pages={85--101},
    year={2022},
    doi={10.1007/s10845-021-01736-6}
}


@incollection{Bentivogli2023,
    title={Enabling Predictive Maintenance on Electric Motors Through a Self-sustainable Wireless Sensor Node},
    author={Andrea Bentivogli and Tommaso Polonelli and Michele Magno and Guido Comai},
    booktitle={Applications in Electronics Pervading Industry, Environment and Society},
    editor={Riccardo Berta and Alessandro De Gloria},
    year={2023},
    publisher={Springer Nature Switzerland AG},
    pages={13-29},
    doi={10.1007/978-3-030-88869-7_2}
}

@article{Sangeetha2017,
    title={An IoT and Machine Learning-Based Predictive Maintenance System for Electrical Motors},
    author={P. Sangeetha and S. Hemamalini},
    journal={IET Signal Processing},
    volume={11},
    number={5},
    pages={604-612},
    year={2017},
    doi={10.1049/iet-spr.2016.0455}
}

@article{Sezdi2019,
    title={The Technical Support: Repair, Preventive Maintenance, and Inspection},
    author={Mana Sezdi},
    booktitle={Biomedical Engineering and its Applications in Healthcare},
    editor={Sudip Paul},
    year={2019},
    publisher={Springer},
    doi={10.1007/978-981-13-3705-5_25}
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%% old 

@article{deepanshu_mehta_2020_rl,
  title   = {State-of-the-art reinforcement learning algorithms},
  volume  = {V8},
  doi     = {10.17577/ijertv8is120332},
  number  = {12},
  journal = {International Journal of Engineering Research and},
  author  = {Deepanshu Mehta},
  year    = {2020}
}
 
@article{liu_wang_qi_ju_2021_superpruner,
  title   = {SuperPruner: Automatic neural network pruning via Super Network},
  volume  = {2021},
  doi     = {10.1155/2021/9971669},
  journal = {Scientific Programming},
  author  = {Liu, Yu and Wang, Yong and Qi, Haojin and Ju, Xiaoming},
  year    = {2021},
  pages   = {1–11}
}

@article{liu_mu_zhang_guo_yang_cheng_sun_2019_metapruning,
  title   = {Metapruning: Meta Learning for Automatic Neural Network channel pruning},
  doi     = {10.1109/iccv.2019.00339},
  journal = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  author  = {Liu, Zechun and Mu, Haoyuan and Zhang, Xiangyu and Guo, Zichao and Yang, Xin and Cheng, Kwang-Ting and Sun, Jian},
  year    = {2019}
} 

@article{frankle_carbin_2019,
  title   = {The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  url     = {https://arxiv.org/abs/1803.03635},
  journal = {arXiv.org},
  author  = {Frankle, Jonathan and Carbin, Michael},
  year    = {2019},
  month   = {Mar}
}

@article{chen_frankle_chang_liu_zhang_wang_carbin_2020,
  title   = {The lottery ticket hypothesis for pre-trained Bert Networks},
  url     = {https://arxiv.org/abs/2007.12223},
  journal = {arXiv.org},
  author  = {Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Wang, Zhangyang and Carbin, Michael},
  year    = {2020},
  month   = {Oct}
} 
 
@article{goyal_ferrara_2018_graph_embedding,
  title   = {Graph embedding techniques, applications, and performance: A survey},
  volume  = {151},
  doi     = {10.1016/j.knosys.2018.03.022},
  journal = {Knowledge-Based Systems},
  author  = {Goyal, Palash and Ferrara, Emilio},
  year    = {2018},
  pages   = {78–94}
} 

 @article{mcculloch_pitts_1943_nervous_activity,
  title   = {A logical calculus of the ideas immanent in nervous activity},
  volume  = {5},
  doi     = {10.1007/bf02478259},
  number  = {4},
  journal = {The Bulletin of Mathematical Biophysics},
  author  = {McCulloch, Warren S. and Pitts, Walter},
  year    = {1943},
  pages   = {115–133}
} 

@article{rosenblatt_1958_perceptron,
  title   = {The Perceptron: A probabilistic model for information storage and organization in the brain.},
  volume  = {65},
  doi     = {10.1037/h0042519},
  number  = {6},
  journal = {Psychological Review},
  author  = {Rosenblatt, F.},
  year    = {1958},
  pages   = {386–408}
} 

@book{bishop_2016,
  place     = {New York, NY},
  title     = {Pattern recognition and machine learning},
  publisher = {Springer New York},
  author    = {Bishop, Christopher M.},
  year      = {2016}
} 

@book{aggarwal_2018,
  place     = {Cham, Switzerland},
  title     = {Neural networks and deep learning: A textbook},
  publisher = {Springer},
  author    = {Aggarwal, Charu C.},
  year      = {2018}
} 

 @article{feng_he_teng_ren_chen_li_2019,
  title   = {Reconstruction of Porous Media from extremely limited information using conditional generative adversarial networks},
  volume  = {100},
  doi     = {10.1103/physreve.100.033308},
  number  = {3},
  journal = {Physical Review E},
  author  = {Feng, Junxi and He, Xiaohai and Teng, Qizhi and Ren, Chao and Chen, Honggang and Li, Yang},
  year    = {2019}
} 

 @inproceedings{dl-healthcare,
  author    = {Muniasamy, Anandhavalli
               and Tabassam, Sehrish
               and Hussain, Mohammad A.
               and Sultana, Habeeba
               and Muniasamy, Vasanthi
               and Bhatnagar, Roheet},
  editor    = {Hassanien, Aboul Ella
               and Azar, Ahmad Taher
               and Gaber, Tarek 
               and Bhatnagar, Roheet
               and F. Tolba, Mohamed},
  title     = {Deep Learning for Predictive Analytics in Healthcare},
  booktitle = {The International Conference on Advanced Machine Learning Technologies and Applications (AMLTA2019)},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {32--42},
  abstract  = {Despite a recent wealth of data and information, the healthcare sector is lacking in actionable knowledge. The healthcare industry faces challenges in essential areas like electronic record management, data integration, and computer-aided diagnoses and disease predictions. It is necessary to reduce healthcare costs and the movement towards personalized healthcare. The rapidly expanding fields of deep learning and predictive analytics has started to play a pivotal role in the evolution of large volume of healthcare data practices and research. Deep learning offers a wide range of tools, techniques, and frameworks to address these challenges. Health data predictive analytics is emerging as a transformative tool that can enable more proactive and preventative treatment options. In a nutshell, this paper focus on the framework for deep learning data analysis to clinical decision making depicts the study on various deep learning techniques and tools in practice as well as the applications of deep learning in healthcare.},
  isbn      = {978-3-030-14118-9}
}

 @article{kumaraswamy_2021,
  title   = {Neural Networks for Data Classification},
  doi     = {10.1016/b978-0-12-820601-0.00011-2},
  journal = {Artificial Intelligence in Data Mining},
  author  = {Kumaraswamy, Balachandra},
  year    = {2021},
  pages   = {109–131}
} 

@article{alharbi_hewahi_2021,
  title   = {Exploring deep neural network capability for intrusion detection using different mobile phones platforms},
  volume  = {10},
  doi     = {10.12785/ijcds/1001123},
  number  = {1},
  journal = {International Journal of Computing and Digital Systems},
  author  = {Alharbi, Nouf Fahad and Hewahi, Nabil M.},
  year    = {2021},
  pages   = {1391–1406}
} 

 @article{kimura_yoshinaga_sekijima_azechi_baba_2019,
  title   = {Convolutional neural network coupled with a transfer-learning approach for time-series flood predictions},
  volume  = {12},
  doi     = {10.3390/w12010096},
  number  = {1},
  journal = {Water},
  author  = {Kimura, Nobuaki and Yoshinaga, Ikuo and Sekijima, Kenji and Azechi, Issaku and Baba, Daichi},
  year    = {2019},
  pages   = {96}
} 

@article{hu_wu_xu_lai_xia_2022,
  title   = {A multi-attack intrusion detection model based on mosaic coded convolutional neural network and centralized encoding},
  volume  = {17},
  doi     = {10.1371/journal.pone.0267910},
  number  = {5},
  journal = {PLOS ONE},
  author  = {Hu, Rong and Wu, Zhongying and Xu, Yong and Lai, Taotao and Xia, Canyu},
  year    = {2022}
} 

@article{feng_feng_chen_cao_zhang_jiao_yu_2020,
  title   = {Generative Adversarial Networks based on collaborative learning and attention mechanism for hyperspectral image classification},
  volume  = {12},
  doi     = {10.3390/rs12071149},
  number  = {7},
  journal = {Remote Sensing},
  author  = {Feng, Jie and Feng, Xueliang and Chen, Jiantong and Cao, Xianghai and Zhang, Xiangrong and Jiao, Licheng and Yu, Tao},
  year    = {2020},
  pages   = {1149}
}


 @article{strubell_ganesh_mccallum_2019,
  title   = {Energy and policy considerations for Deep Learning in NLP},
  doi     = {10.18653/v1/p19-1355},
  journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  author  = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  year    = {2019}
} 



@article{gupta2020learning,
  title   = {Learning to prune deep neural networks via reinforcement learning},
  author  = {Gupta, Manas and Aravindan, Siddharth and Kalisz, Aleksandra and Chandrasekhar, Vijay and Jie, Lin},
  journal = {arXiv preprint arXiv:2007.04756},
  year    = {2020}
}

 @article{he_lin_liu_wang_li_han_2018,
  title   = {AMC: Automl for model compression and acceleration on mobile devices},
  doi     = {10.1007/978-3-030-01234-2_48},
  journal = {Computer Vision – ECCV 2018},
  author  = {He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
  year    = {2018},
  pages   = {815–832}
} 



 @article{goodfellow_pouget-abadie_mirza_xu_warde-farley_ozair_courville_bengio_2020,
  title   = {Generative Adversarial Networks},
  volume  = {63},
  doi     = {10.1145/3422622},
  number  = {11},
  journal = {Communications of the ACM},
  author  = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year    = {2020},
  pages   = {139–144}
} 

 @inproceedings{attention_is_all_you_need,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Attention is All you Need},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@inproceedings{He_2016_CVPR,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2016}
}

@article{dong_niu_li_xie_zou_ye_wei_pan_2022,
  title   = {Prior-guided one-shot neural architecture search},
  url     = {https://arxiv.org/abs/2206.13329v1},
  journal = {arXiv.org},
  author  = {Dong, Peijie and Niu, Xin and Li, Lujun and Xie, Linzhen and Zou, Wenbin and Ye, Tian and Wei, Zimian and Pan, Hengyue},
  year    = {2022},
  month   = {Jun}
} 

 @article{ZHOU202057,
  title    = {Graph neural networks: A review of methods and applications},
  journal  = {AI Open},
  volume   = {1},
  pages    = {57-81},
  year     = {2020},
  issn     = {2666-6510},
  doi      = {https://doi.org/10.1016/j.aiopen.2021.01.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S2666651021000012},
  author   = {Jie Zhou and Ganqu Cui and Shengding Hu and Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
  keywords = {Deep learning, Graph neural network},
  abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.}
}

@article{amini2018spatial,
  title   = {Spatial uncertainty sampling for end-to-end control},
  author  = {Amini, Alexander and Soleimany, Ava and Karaman, Sertac and Rus, Daniela},
  journal = {arXiv preprint arXiv:1805.04829},
  year    = {2018}
}

@article{han2015learning,
  title   = {Learning both weights and connections for efficient neural network},
  author  = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal = {Advances in neural information processing systems},
  volume  = {28},
  year    = {2015}
}

@article{kaelbling_littman_moore_1996,
  title   = {Reinforcement learning:  A survey},
  volume  = {4},
  doi     = {10.1613/jair.301},
  journal = {Journal of Artificial Intelligence Research},
  author  = {Kaelbling, L. P. and Littman, M. L. and Moore, A. W.},
  year    = {1996},
  pages   = {237–285}
} 


@article{xie_jiang_luo_yu_2020,
  title   = {Model compression via pruning and knowledge distillation for person re-identification},
  volume  = {12},
  doi     = {10.1007/s12652-020-02312-4},
  number  = {2},
  journal = {Journal of Ambient Intelligence and Humanized Computing},
  author  = {Xie, Haonan and Jiang, Wei and Luo, Hao and Yu, Hongyan},
  year    = {2020},
  pages   = {2149–2161}
} 

@article{sutton_1988,
  title   = {Learning to predict by the methods of temporal differences},
  volume  = {3},
  doi     = {10.1007/bf00115009},
  number  = {1},
  journal = {Machine Learning},
  author  = {Sutton, Richard S.},
  year    = {1988},
  pages   = {9–44}
} 

@article{watkins_dayan_1992,
  title   = {Q-learning},
  volume  = {8},
  doi     = {10.1007/bf00992698},
  number  = {3-4},
  journal = {Machine Learning},
  author  = {Watkins, Christopher J. and Dayan, Peter},
  year    = {1992},
  pages   = {279–292}
} 

@inproceedings{deep-reinforcement-learning-2019,
  author    = {Koo, Jaehoon and Mendiratta, Veena B. and Rahman, Muntasir Raihan and Walid, Anwar},
  booktitle = {2019 15th International Conference on Network and Service Management (CNSM)},
  title     = {Deep Reinforcement Learning for Network Slicing with Heterogeneous Resource Requirements and Time Varying Traffic Dynamics},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.23919/CNSM46954.2019.9012702}
}

@phdthesis{phdthesis_kouridi_2020,
  author = {Kouridi, Christina},
  year   = {2020},
  month  = {09},
  pages  = {},
  title  = {Syntactic language understanding for generalisation in reinforcement learning},
  doi    = {10.13140/RG.2.2.21732.81282}
}


 @book{gross_2006,
  place     = {Boca Raton},
  title     = {Graph theory and its applications},
  publisher = {Chapman \& Hall/CRC},
  author    = {Gross, Jonathan L.},
  year      = {2006}
} 



  @article{srinivas_babu_2015,
  title   = {Data-free parameter pruning for deep neural networks},
  doi     = {10.5244/c.29.31},
  journal = {Procedings of the British Machine Vision Conference 2015},
  author  = {Srinivas, Suraj and Babu, R. Venkatesh},
  year    = {2015}
} 


@techreport{bengio2003adaptive,
  title       = {Adaptive importance sampling to accelerate training of a neural probabilistic language model},
  author      = {Bengio, Yoshua and Sen{\'e}cal, Jean-S{\'e}bastien},
  year        = {2003},
  institution = {IDIAP}
}

@inproceedings{perozzi2014deepwalk,
  title     = {Deepwalk: Online learning of social representations},
  author    = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
  booktitle = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages     = {701--710},
  year      = {2014}
}

@inproceedings{grover2016node2vec,
  title     = {node2vec: Scalable feature learning for networks},
  author    = {Grover, Aditya and Leskovec, Jure},
  booktitle = {Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages     = {855--864},
  year      = {2016}
}

@article{kipf2016semi,
  title   = {Semi-supervised classification with graph convolutional networks},
  author  = {Kipf, Thomas N and Welling, Max},
  journal = {arXiv preprint arXiv:1609.02907},
  year    = {2016}
}

@inproceedings{tang2015line,
  title     = {Line: Large-scale information network embedding},
  author    = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
  booktitle = {Proceedings of the 24th international conference on world wide web},
  pages     = {1067--1077},
  year      = {2015}
}

@article{hamilton2017representation,
  title   = {Representation learning on graphs: Methods and applications},
  author  = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal = {arXiv preprint arXiv:1709.05584},
  year    = {2017}
}


@article{li2016pruning,
  title   = {Pruning filters for efficient convnets},
  author  = {Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal = {arXiv preprint arXiv:1608.08710},
  year    = {2016}
}

@article{he2017channel,
  title     = {Channel pruning for accelerating very deep neural networks},
  author    = {He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {1389--1397},
  year      = {2017}
}

@article{zhuang2018discrimination,
  title   = {Discrimination-aware channel pruning for deep neural networks},
  author  = {Zhuang, Zhuangwei and Tan, Mingkui and Zhuang, Bohan and Liu, Jing and Guo, Yong and Wu, Qingyao and Huang, Junzhou and Zhu, Jinhui},
  journal = {Advances in neural information processing systems},
  volume  = {31},
  year    = {2018}
}

@article{sarvani2022hrel,
  title     = {Hrel: Filter pruning based on high relevance between activation maps and class labels},
  author    = {Sarvani, CH and Ghorai, Mrinmoy and Dubey, Shiv Ram and Basha, SH Shabbeer},
  journal   = {Neural Networks},
  volume    = {147},
  pages     = {186--197},
  year      = {2022},
  publisher = {Elsevier}
}

@article{anwar2017structured,
  title     = {Structured pruning of deep convolutional neural networks},
  author    = {Anwar, Sajid and Hwang, Kyuyeon and Sung, Wonyong},
  journal   = {ACM Journal on Emerging Technologies in Computing Systems (JETC)},
  volume    = {13},
  number    = {3},
  pages     = {1--18},
  year      = {2017},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{obd,
  author    = {LeCun, Yann and Denker, John and Solla, Sara},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {D. Touretzky},
  pages     = {},
  publisher = {Morgan-Kaufmann},
  title     = {Optimal Brain Damage},
  url       = {https://proceedings.neurips.cc/paper_files/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf},
  volume    = {2},
  year      = {1989}
}

@article{frankle2020pruning,
  title   = {Pruning neural networks at initialization: Why are we missing the mark?},
  author  = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal = {arXiv preprint arXiv:2009.08576},
  year    = {2020}
}

@article{cai2022structured,
  title   = {Structured pruning is all you need for pruning CNNs at initialization},
  author  = {Cai, Yaohui and Hua, Weizhe and Chen, Hongzheng and Suh, G Edward and De Sa, Christopher and Zhang, Zhiru},
  journal = {arXiv preprint arXiv:2203.02549},
  year    = {2022}
}

@article{han2015deep,
  title   = {Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author  = {Han, Song and Mao, Huizi and Dally, William J},
  journal = {arXiv preprint arXiv:1510.00149},
  year    = {2015}
}

@article{molchanov2016pruning,
  title   = {Pruning convolutional neural networks for resource efficient inference},
  author  = {Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal = {arXiv preprint arXiv:1611.06440},
  year    = {2016}
}

@article{wen2016learning,
  title   = {Learning structured sparsity in deep neural networks},
  author  = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal = {Advances in neural information processing systems},
  volume  = {29},
  year    = {2016}
}

@article{frankle2019stabilizing,
  title   = {Stabilizing the lottery ticket hypothesis},
  author  = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal = {arXiv preprint arXiv:1903.01611},
  year    = {2019}
}

@techreport{krizhevsky2009learning,
  author                      = {Krizhevsky, Alex and Hinton, Geoffrey},
  address                     = {Toronto, Ontario},
  institution                 = {University of Toronto},
  number                      = {0},
  publisher                   = {Technical report, University of Toronto},
  title                       = {Learning multiple layers of features from tiny images},
  year                        = {2009},
  title_with_no_special_chars = {Learning multiple layers of features from tiny images},
  url                         = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}
}

@article{simonyan2014very,
  title   = {Very deep convolutional networks for large-scale image recognition},
  author  = {Simonyan, Karen and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1409.1556},
  year    = {2014}
}

@inproceedings{He_2016_CVPR,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2016}
}

@article{Yamamoto2018PCASPC,
  title   = {PCAS: Pruning Channels with Attention Statistics},
  author  = {Kohei Yamamoto and Kurato Maeno},
  journal = {ArXiv},
  year    = {2018},
  volume  = {abs/1806.05382},
  url     = {https://api.semanticscholar.org/CorpusID:49212434}
}

@inproceedings{handaoui2020releaser,
  title        = {Releaser: A reinforcement learning strategy for optimizing utilization of ephemeral cloud resources},
  author       = {Handaoui, Mohamed and Dartois, Jean-Emile and Boukhobza, Jalil and Barais, Olivier and d'Orazio, Laurent},
  booktitle    = {2020 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)},
  pages        = {65--73},
  year         = {2020},
  organization = {IEEE}
}

@inproceedings{Liessner2018DeepRL,
  title     = {Deep Reinforcement Learning for Advanced Energy Management of Hybrid Electric Vehicles},
  author    = {Roman Liessner and Christian G. Schroer and Ansgar Malte Dietermann and Bernard B{\"a}ker},
  booktitle = {International Conference on Agents and Artificial Intelligence},
  year      = {2018},
  url       = {https://api.semanticscholar.org/CorpusID:28072831}
}

@inproceedings{yoseph2019,
  author    = {Yoseph, Fahed and Heikkilä, Markku and Howard, Daniel},
  booktitle = {2019 International Conference on Machine Learning and Data Engineering (iCMLDE)},
  title     = {Outliers Identification Model in Point-of-Sales Data Using Enhanced Normal Distribution Method},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {72-78},
  doi       = {10.1109/iCMLDE49015.2019.00024}
}

@article{lin2020channel,
  title   = {Channel pruning via automatic structure search},
  author  = {Lin, Mingbao and Ji, Rongrong and Zhang, Yuxin and Zhang, Baochang and Wu, Yongjian and Tian, Yonghong},
  journal = {arXiv preprint arXiv:2001.08565},
  year    = {2020}
}

@article{CHEN202135,
  title   = {CCPrune: Collaborative channel pruning for learning compact convolutional networks},
  journal = {Neurocomputing},
  volume  = {451},
  pages   = {35-45},
  year    = {2021},
  issn    = {0925-2312},
  doi     = {https://doi.org/10.1016/j.neucom.2021.04.063},
  url     = {https://www.sciencedirect.com/science/article/pii/S0925231221006056},
  author  = {Yanming Chen and Xiang Wen and Yiwen Zhang and Weisong Shi}
}

@thesis{pfe2022,
  author = {Lyes Douag and Lokmane Sadani},
  title  = {Etude et implémentation de méthodes pour l’optimisation des architectures neuronales entièrement connectées},
  school = {ESI},
  year   = {2022},
  type   = {Master's thesis}
}

@article{hu2016network,
  title   = {Network trimming: A data-driven neuron pruning approach towards efficient deep architectures},
  author  = {Hu, Hengyuan and Peng, Rui and Tai, Yu-Wing and Tang, Chi-Keung},
  journal = {arXiv preprint arXiv:1607.03250},
  year    = {2016}
}

@inproceedings{luo2017thinet,
  title     = {Thinet: A filter level pruning method for deep neural network compression},
  author    = {Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {5058--5066},
  year      = {2017}
}

@article{mishra2020survey,
  title   = {A survey on deep neural network compression: Challenges, overview, and solutions},
  author  = {Mishra, Rahul and Gupta, Hari Prabhat and Dutta, Tanima},
  journal = {arXiv preprint arXiv:2010.03954},
  year    = {2020}
}

@inproceedings{singh2019stability,
  title        = {Stability based filter pruning for accelerating deep cnns},
  author       = {Singh, Pravendra and Kadi, Vinay Sameer Raja and Verma, Nikhil and Namboodiri, Vinay P},
  booktitle    = {2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages        = {1166--1174},
  year         = {2019},
  organization = {IEEE}
}

@article{chen2021only,
  title   = {Only train once: A one-shot neural network training and pruning framework},
  author  = {Chen, Tianyi and Ji, Bo and Ding, Tianyu and Fang, Biyi and Wang, Guanyi and Zhu, Zhihui and Liang, Luming and Shi, Yixin and Yi, Sheng and Tu, Xiao},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  pages   = {19637--19651},
  year    = {2021}
}


@book{Goodfellow-et-al-2016,
  title     = {Deep Learning},
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year      = {2016},
  publisher = {MIT Press}
}
@book{bellman1957dynamic,
  title     = {Dynamic Programming},
  author    = {Bellman, Richard},
  year      = {1957},
  publisher = {Princeton University Press}
}
@book{sutton2018reinforcement,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  year      = {2018},
  publisher = {MIT Press}
}
@book{wiering2012reinforcement,
  title     = {Reinforcement Learning: State-of-the-Art},
  editor    = {Wiering, Marco and van Otterlo, Martijn},
  year      = {2012},
  publisher = {Springer}
}
