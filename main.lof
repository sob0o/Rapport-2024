\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.1}\else \textLR {1.1}\fi }{\ignorespaces Le fonctionnement d'un neurone artificiel [\blx@tocontentsinit {0}\cite {mcculloch_pitts_1943_nervous_activity}].}}{7}{figure.caption.7}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.1}\else \textLR {1.2}\fi }{\ignorespaces Les fonctions d'activations couramment utilisées [\blx@tocontentsinit {0}\cite {feng_he_teng_ren_chen_li_2019}].}}{8}{figure.caption.8}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.1}\else \textLR {1.3}\fi }{\ignorespaces Schéma simple d'un réseau de neurones feedforward [\blx@tocontentsinit {0}\cite {dl-healthcare}].}}{10}{figure.caption.9}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.1}\else \textLR {1.4}\fi }{\ignorespaces Exemple d'un réseau de neurones récurrent [\blx@tocontentsinit {0}\cite {kumaraswamy_2021}].}}{11}{figure.caption.10}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.1}\else \textLR {1.5}\fi }{\ignorespaces Le fonctionnement d'un réseau neuronal convolutif [\blx@tocontentsinit {0}\cite {alharbi_hewahi_2021}].}}{12}{figure.caption.11}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.1}\else \textLR {1.6}\fi }{\ignorespaces Exemple du fonctionnement d'une couche convolutive [\blx@tocontentsinit {0}\cite {kimura_yoshinaga_sekijima_azechi_baba_2019}].}}{13}{figure.caption.13}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.1}\else \textLR {1.7}\fi }{\ignorespaces Exemples de pooling maximal et pooling moyen [\blx@tocontentsinit {0}\cite {hu_wu_xu_lai_xia_2022}].}}{13}{figure.caption.15}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {8.1}\else \textLR {1.8}\fi }{\ignorespaces Un modèle de réseau générateur adversaire (GAN) [\blx@tocontentsinit {0}\cite {feng_feng_chen_cao_zhang_jiao_yu_2020}].}}{14}{figure.caption.16}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {9.1}\else \textLR {1.9}\fi }{\ignorespaces Architecture d'un reseau de neurones de transformation (Transformer) [\blx@tocontentsinit {0}\cite {attention_is_all_you_need}].}}{15}{figure.caption.17}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {10.1}\else \textLR {1.10}\fi }{\ignorespaces Un bloc régulier (gauche) et un bloc résiduel (droite) [\blx@tocontentsinit {0}\cite {dong_niu_li_xie_zou_ye_wei_pan_2022}].}}{16}{figure.caption.18}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {11.1}\else \textLR {1.11}\fi }{\ignorespaces Le pipeline de conception générale pour un modèle GNN [\blx@tocontentsinit {0}\cite {ZHOU202057}].}}{17}{figure.caption.19}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {12.1}\else \textLR {1.12}\fi }{\ignorespaces Fonction de taux d’erreur [\blx@tocontentsinit {0}\cite {amini2018spatial}].}}{19}{figure.caption.20}%
\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.2}\else \textLR {2.1}\fi }{\ignorespaces Le fonctionnement d'un neurone artificiel [\blx@tocontentsinit {0}\cite {mcculloch_pitts_1943_nervous_activity}].}}{25}{figure.caption.21}%
\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.3}\else \textLR {3.1}\fi }{\ignorespaces Présentation du processus d'élagage.}}{29}{figure.caption.22}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.3}\else \textLR {3.2}\fi }{\ignorespaces Schéma global du processus d'élagage.}}{30}{figure.caption.23}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.3}\else \textLR {3.3}\fi }{\ignorespaces Nombre des FLOPs dans le modèle.}}{35}{figure.caption.28}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.3}\else \textLR {3.4}\fi }{\ignorespaces Illustration du mécanisme d’élagage des canaux [\blx@tocontentsinit {0}\cite {Yamamoto2018PCASPC}].}}{36}{figure.caption.29}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.3}\else \textLR {3.5}\fi }{\ignorespaces Schéma de présentation de l'algorithme DDPG [\blx@tocontentsinit {0}\cite {handaoui2020releaser}].}}{37}{figure.caption.30}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.3}\else \textLR {3.6}\fi }{\ignorespaces Courbe de la distribution gaussienne [\blx@tocontentsinit {0}\cite {yoseph2019}].}}{39}{figure.caption.32}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.3}\else \textLR {3.7}\fi }{\ignorespaces Structure de base de l'agent acteur-critique DDPG. L'acteur prend l'état \textit {s} comme entrée et produit une action basée sur la politique déterministe $\mu $ comme résultat. Le critique prend à la fois l'état et l'action choisie par l'acteur comme entrée et fournit en sortie une valeur \textit {Q} [\blx@tocontentsinit {0}\cite {Liessner2018DeepRL}].}}{40}{figure.caption.36}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {8.3}\else \textLR {3.8}\fi }{\ignorespaces Schéma représentant le processus d'entraînement de l'agent DDPG. L'agent est entraîné pour un nombre fixe d'épisodes et, dans chaque épisode, un nombre fixe de pas de temps (timesteps).}}{43}{figure.caption.39}%
\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.4}\else \textLR {4.1}\fi }{\ignorespaces Les classes du jeu de données CIFAR-10.}}{47}{figure.caption.40}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.4}\else \textLR {4.2}\fi }{\ignorespaces Un bloc résiduel de base comme sur la figure \ref {fig:architectures} pour ResNet-34 [\blx@tocontentsinit {0}\cite {He_2016_CVPR}].}}{49}{figure.caption.42}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.4}\else \textLR {4.3}\fi }{\ignorespaces Les architectures des modèles utilisés. A gauche: le modèle VGG-19. Au milieu: un réseau simple de 34 couches. À droite: le modèle ResNet-34 [\blx@tocontentsinit {0}\cite {He_2016_CVPR}].}}{50}{figure.caption.43}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.4}\else \textLR {4.4}\fi }{\ignorespaces Python.}}{51}{figure.caption.44}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.4}\else \textLR {4.5}\fi }{\ignorespaces NumPy.}}{52}{figure.caption.45}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.4}\else \textLR {4.6}\fi }{\ignorespaces Matplotlib.}}{52}{figure.caption.46}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.4}\else \textLR {4.7}\fi }{\ignorespaces Pytorch.}}{53}{figure.caption.47}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {8.4}\else \textLR {4.8}\fi }{\ignorespaces Torchvision.}}{54}{figure.caption.48}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {9.4}\else \textLR {4.9}\fi }{\ignorespaces NNI (Neural Network Intelligence).}}{54}{figure.caption.49}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {10.4}\else \textLR {4.10}\fi }{\ignorespaces Google Colab.}}{55}{figure.caption.50}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {11.4}\else \textLR {4.11}\fi }{\ignorespaces Google Drive.}}{55}{figure.caption.51}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {12.4}\else \textLR {4.12}\fi }{\ignorespaces Statistiques des canaux restants dans les couches de convolution de VGG-19.}}{58}{figure.caption.53}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {13.4}\else \textLR {4.13}\fi }{\ignorespaces Comparaison entre les taux d'élagage des FLOPs et des paramètres des trois méthodes d'élagage pour le réseau ResNet-34.}}{59}{figure.caption.55}%
