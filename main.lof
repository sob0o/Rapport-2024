\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.1}\else \textLR {1.1}\fi }{\ignorespaces Le fonctionnement d'un neurone artificiel [\blx@tocontentsinit {0}\cite {mcculloch_pitts_1943_nervous_activity}].}}{7}{figure.caption.7}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.1}\else \textLR {1.2}\fi }{\ignorespaces Les fonctions d'activations couramment utilisées [\blx@tocontentsinit {0}\cite {feng_he_teng_ren_chen_li_2019}].}}{8}{figure.caption.8}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.1}\else \textLR {1.3}\fi }{\ignorespaces Schéma simple d'un réseau de neurones feedforward [\blx@tocontentsinit {0}\cite {dl-healthcare}].}}{10}{figure.caption.9}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.1}\else \textLR {1.4}\fi }{\ignorespaces Exemple d'un réseau de neurones récurrent [\blx@tocontentsinit {0}\cite {kumaraswamy_2021}].}}{11}{figure.caption.10}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.1}\else \textLR {1.5}\fi }{\ignorespaces Architecture d'un bloc LSTM [\blx@tocontentsinit {0}\cite {fawaz2019long}].}}{12}{figure.caption.12}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.1}\else \textLR {1.6}\fi }{\ignorespaces Le fonctionnement d'un réseau neuronal convolutif [\blx@tocontentsinit {0}\cite {alharbi_hewahi_2021}].}}{13}{figure.caption.13}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.1}\else \textLR {1.7}\fi }{\ignorespaces Exemple du fonctionnement d'une couche convolutive [\blx@tocontentsinit {0}\cite {kimura_yoshinaga_sekijima_azechi_baba_2019}].}}{14}{figure.caption.15}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {8.1}\else \textLR {1.8}\fi }{\ignorespaces Exemples de pooling maximal et pooling moyen [\blx@tocontentsinit {0}\cite {hu_wu_xu_lai_xia_2022}].}}{15}{figure.caption.17}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {9.1}\else \textLR {1.9}\fi }{\ignorespaces Un bloc régulier (gauche) et un bloc résiduel (droite) [\blx@tocontentsinit {0}\cite {dong_niu_li_xie_zou_ye_wei_pan_2022}].}}{15}{figure.caption.18}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {10.1}\else \textLR {1.10}\fi }{\ignorespaces Le pipeline de conception générale pour un modèle GNN [\blx@tocontentsinit {0}\cite {ZHOU202057}].}}{16}{figure.caption.19}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {11.1}\else \textLR {1.11}\fi }{\ignorespaces Fonction de taux d’erreur [\blx@tocontentsinit {0}\cite {amini2018spatial}].}}{18}{figure.caption.20}%
\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.2}\else \textLR {2.1}\fi }{\ignorespaces Le fonctionnement d'un neurone artificiel [\blx@tocontentsinit {0}\cite {kingma_welling_auto_encoding}].}}{26}{figure.caption.23}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.2}\else \textLR {2.2}\fi }{\ignorespaces Un modèle de réseau générateur adversaire (GAN) [\blx@tocontentsinit {0}\cite {feng_feng_chen_cao_zhang_jiao_yu_2020}].}}{30}{figure.caption.33}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.2}\else \textLR {2.3}\fi }{\ignorespaces Quelques images générées par le modèle StyleGAN sur le site 'This Person Does Not Exist'[\blx@tocontentsinit {0}\cite {thispersondoesnotexist}].}}{31}{figure.caption.38}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.2}\else \textLR {2.4}\fi }{\ignorespaces Chaîne de Markov du processus de diffusion [\blx@tocontentsinit {0}\cite {ho2020denoising}].}}{32}{figure.caption.39}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.2}\else \textLR {2.5}\fi }{\ignorespaces Illustration des Processus de Diffusion : Forward Process et Reverse Process.}}{34}{figure.caption.42}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.2}\else \textLR {2.6}\fi }{\ignorespaces Architecture d'un reseau de neurones de transformation (Transformer) [\blx@tocontentsinit {0}\cite {attention_is_all_you_need}].}}{37}{figure.caption.49}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.2}\else \textLR {2.7}\fi }{\ignorespaces Architecture d'un reseau de neurones de transformation (Transformer) [\blx@tocontentsinit {0}\cite {attention_is_all_you_need}].}}{39}{figure.caption.52}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {1.5}\else \textLR {5.1}\fi }{\ignorespaces Les classes du jeu de données CIFAR-10.}}{46}{figure.caption.53}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {2.5}\else \textLR {5.2}\fi }{\ignorespaces Un bloc résiduel de base comme sur la figure \ref {fig:architectures} pour ResNet-34 [\blx@tocontentsinit {0}\cite {He_2016_CVPR}].}}{48}{figure.caption.55}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {3.5}\else \textLR {5.3}\fi }{\ignorespaces Les architectures des modèles utilisés. A gauche: le modèle VGG-19. Au milieu: un réseau simple de 34 couches. À droite: le modèle ResNet-34 [\blx@tocontentsinit {0}\cite {He_2016_CVPR}].}}{49}{figure.caption.56}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {4.5}\else \textLR {5.4}\fi }{\ignorespaces Python.}}{50}{figure.caption.57}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {5.5}\else \textLR {5.5}\fi }{\ignorespaces NumPy.}}{51}{figure.caption.58}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {6.5}\else \textLR {5.6}\fi }{\ignorespaces Matplotlib.}}{51}{figure.caption.59}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {7.5}\else \textLR {5.7}\fi }{\ignorespaces Pytorch.}}{52}{figure.caption.60}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {8.5}\else \textLR {5.8}\fi }{\ignorespaces Torchvision.}}{53}{figure.caption.61}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {9.5}\else \textLR {5.9}\fi }{\ignorespaces NNI (Neural Network Intelligence).}}{53}{figure.caption.62}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {10.5}\else \textLR {5.10}\fi }{\ignorespaces Google Colab.}}{54}{figure.caption.63}%
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {11.5}\else \textLR {5.11}\fi }{\ignorespaces Google Drive.}}{54}{figure.caption.64}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {12.5}\else \textLR {5.12}\fi }{\ignorespaces Statistiques des canaux restants dans les couches de convolution de VGG-19.}}{57}{figure.caption.66}%
\setforeignlanguage {french}
\setforeignlanguage {french}
\contentsline {figure}{\numberline {\if@rl \I {13.5}\else \textLR {5.13}\fi }{\ignorespaces Comparaison entre les taux d'élagage des FLOPs et des paramètres des trois méthodes d'élagage pour le réseau ResNet-34.}}{58}{figure.caption.68}%
